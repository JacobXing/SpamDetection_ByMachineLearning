{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "print(scipy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(numpy.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samhardyhey/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py:1215: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code, glob, local_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 3.04 s, total: 30.4 s\n",
      "Wall time: 33.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samhardyhey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/samhardyhey/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# raw data preprocessing\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# define import/export directories\n",
    "dirs = {'static_import': '../../data_sets/honey_pot/preprocessed/FinalDataFull.csv.arff',\n",
    "       'static_export': '../../data_sets/honey_pot/final_features/static_features.csv',\n",
    "       'dynamic_imports': ['../../data_sets/honey_pot/raw/cp_tweets.csv',\n",
    "                             '../../data_sets/honey_pot/raw/lu_tweets.csv'],\n",
    "       'dynamic_export':'../../data_sets/honey_pot/preprocessed/dynamic_features_intermediate.csv'}\n",
    "\n",
    "#preprocess all static features\n",
    "def preprocess_static_features(import_path):\n",
    "    data = arff.loadarff(import_path)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    \n",
    "    #correct for usertype boolean type\n",
    "    df['UserType'] = df['UserType'].astype(int)\n",
    "    \n",
    "    #drop any duplicate entries\n",
    "    return df.drop_duplicates(['UserID'])\n",
    "\n",
    "#preprocess all dynamic features\n",
    "def preprocess_dynamic_features(import_paths):\n",
    "    cp_tweets = preprocess_tweet_set(import_paths[0])\n",
    "    lu_tweets = preprocess_tweet_set(import_paths[1])\n",
    "    \n",
    "    #ensure cp and lu tweet ID's are complimentary - disjoint cp/lu users groups\n",
    "    cp_tweets_set = cp_tweets.loc[~cp_tweets['UserID'].isin(lu_tweets['UserID'])] #negated match\n",
    "    lu_tweets_set = lu_tweets.loc[~lu_tweets['UserID'].isin(cp_tweets['UserID'])]\n",
    "    \n",
    "    #flag as illegitimate/legitimate users\n",
    "    cp_tweets_set['UserType'] = 1\n",
    "    lu_tweets_set['UserType'] = 0\n",
    "    \n",
    "    #merge data frames\n",
    "    return pd.concat([cp_tweets_set, lu_tweets_set])\n",
    "\n",
    "#read in single user tweet set\n",
    "def preprocess_tweet_set(tweets_path):\n",
    "    tweets = pd.read_csv(tweets_path)\n",
    "    \n",
    "    #variable removal\n",
    "    tweets = tweets.drop(['TweetID','CreatedAt'], axis=1) #strip unnecessary variables\n",
    "    tweets['UserID'] = pd.to_numeric(tweets['UserID'], errors='coerce') #flag NAN entries in UserID column\n",
    "    tweets = tweets.dropna(subset=['UserID']) #remove row entries with malformed UserID\n",
    "\n",
    "    #tweet collating\n",
    "    tweets = tweets.groupby(['UserID'])['Tweet'].apply(list) #groupby userID, pool tweets into single list\n",
    "    tweetJoin = lambda x: ' '.join(x) #join tweets together into single document\n",
    "    tweets = tweets.apply(tweetJoin)\n",
    "\n",
    "    #dataframe reformatting\n",
    "    tweets = tweets.to_frame() #cast back to frame\n",
    "    tweets = tweets.reset_index() #reset/adjust index\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "#find union of two dataframes based upon given value\n",
    "def square_frames(df_a, df_b):\n",
    "    df_a_set = df_a.loc[df_a['UserID'].isin(df_b['UserID'])] #ensure for match\n",
    "    df_b_set = df_b.loc[df_b['UserID'].isin(df_a['UserID'])]\n",
    "    \n",
    "    df_a_set = df_a_set.sample(n=100, axis=0) #return small sample for prototyping speed\n",
    "    df_b_set = df_b_set.loc[df_b['UserID'].isin(df_a_set['UserID'])] #match user type\n",
    "    \n",
    "    return df_a_set, df_b_set #retain original frame housing\n",
    "\n",
    "#export frames\n",
    "def export_frames(frames, locations):\n",
    "    for frame,location in zip(frames,locations):\n",
    "        export_csv(frame,location)\n",
    "    \n",
    "# preprocess static and dynamic dataframes\n",
    "static_df = preprocess_static_features(dirs['static_import'])\n",
    "dynamic_df = preprocess_dynamic_features(dirs['dynamic_imports'])\n",
    "\n",
    "#square frames, export as intermediate csv files\n",
    "static_df,dynamic_df = square_frames(static_df, dynamic_df)\n",
    "export_frames([static_df,dynamic_df], [dirs['static_export'],dirs['dynamic_export']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "CPU times: user 22.3 s, sys: 457 ms, total: 22.7 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Stopword generation, Lemmatization, Tokenizer object generation\n",
    "#Vector fitting => bag of words model utilizing count vectorizer\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import wordpunct_tokenize, WordNetLemmatizer, sent_tokenize, pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize constants, lematizer, punctuation and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "# define/return stopwords\n",
    "def define_sw():\n",
    "    custom_stop_words = ['–', '\\u2019', 'u', '\\u201d', '\\u201d.',\n",
    "                         '\\u201c', 'say', 'saying', 'sayings',\n",
    "                         'says', 'us', 'un', '.\\\"', 'would',\n",
    "                         'let', '.”', 'said', ',”', 'ax','max',\n",
    "                         'b8f','g8v','a86','pl','145','ld9','0t',\n",
    "                         '34u']\n",
    "    return set(sw.words('english') + custom_stop_words)\n",
    "\n",
    "# collapse word inflections into single representation\n",
    "def lemmatize(token, tag):\n",
    "    tag = {\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV,\n",
    "        'J': wordnet.ADJ\n",
    "    }.get(tag[0], wordnet.NOUN)\n",
    "\n",
    "    return lemmatizer.lemmatize(token, tag)\n",
    "\n",
    "# tokenize corpus\n",
    "def cab_tokenizer(document):\n",
    "    tokens = []\n",
    "    sw = define_sw()\n",
    "\n",
    "    # split the document into sentences\n",
    "    for sent in sent_tokenize(document):\n",
    "        # tokenize each sentence\n",
    "        for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "            # preprocess and remove unnecessary characters\n",
    "            token = token.lower()\n",
    "            token = token.strip()\n",
    "            token = token.strip('_')\n",
    "            token = token.strip('*')\n",
    "\n",
    "            # If punctuation, ignore token and continue\n",
    "            if all(char in punct for char in token):\n",
    "                continue\n",
    "\n",
    "            # If stopword, ignore token and continue\n",
    "            if token in sw:\n",
    "                continue\n",
    "\n",
    "            # Lemmatize the token and add back to the token\n",
    "            lemma = lemmatize(token, tag)\n",
    "\n",
    "            # Append lemmatized token to list\n",
    "            tokens.append(lemma)\n",
    "    return tokens\n",
    "\n",
    "#generate term frequency vector\n",
    "def generate_vector():\n",
    "    return CountVectorizer(tokenizer=cab_tokenizer,ngram_range=(1,2),\n",
    "                                   min_df=0.15, max_df=0.85)\n",
    "\n",
    "#fit count vectoizer to the supplied corpus, return term frequency matrix/feature names\n",
    "def vectorize(tf_vectorizer, df):\n",
    "    df = df.reindex(columns=['Tweet']) #reindex on tweet\n",
    "    \n",
    "    tf_matrix = tf_vectorizer.fit_transform(df['Tweet'])\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "    return tf_matrix, tf_feature_names\n",
    "\n",
    "#generate and apply count vector to corpus\n",
    "cv = generate_vector()\n",
    "tf_matrix, tf_feature_names = vectorize(cv, dynamic_df)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dt_entropy     goss0     goss1     goss2     goss3     goss4     loss0  \\\n",
      "0     0.693860  0.058200  0.063699 -0.072929 -0.011895 -0.054851  0.627644   \n",
      "1     0.012444  0.182154 -0.068166 -0.072883 -0.011720 -0.054798  0.894427   \n",
      "2     0.007742 -0.091207 -0.068207 -0.072924 -0.011877  0.277282 -0.223606   \n",
      "3     0.440353  0.141404 -0.067990 -0.072710 -0.011064 -0.005917  0.881105   \n",
      "4     0.611038 -0.010845  0.137057 -0.072924 -0.011876 -0.054845  0.151183   \n",
      "5     0.751819  0.110673 -0.020287 -0.045272 -0.011869 -0.054843  0.871325   \n",
      "6     0.009398  0.182257 -0.068193 -0.072911 -0.011822 -0.054828  0.894427   \n",
      "7     1.203447 -0.043998  0.085158 -0.020264 -0.011844 -0.016669 -0.069472   \n",
      "8     0.671484  0.013153 -0.068192 -0.072909 -0.011819  0.150507  0.317059   \n",
      "9     0.890678 -0.091043  0.094644 -0.052922 -0.011229  0.067494 -0.395252   \n",
      "10    0.750238  0.112128 -0.068154 -0.042278 -0.011677 -0.005460  0.874273   \n",
      "11    0.006640 -0.091216  0.222495 -0.072933 -0.011911 -0.054856 -0.223606   \n",
      "12    0.462179 -0.087983  0.179738 -0.072946 -0.011960 -0.009897 -0.254688   \n",
      "13    0.172280  0.174548 -0.066150 -0.070915 -0.004165 -0.052451  0.894427   \n",
      "14    1.293800  0.010327  0.018194 -0.005171 -0.011880 -0.023697  0.566073   \n",
      "15    1.133542 -0.004110 -0.042608  0.072125 -0.011789 -0.026804  0.282825   \n",
      "16    0.006195 -0.091219  0.222510 -0.072937 -0.011925 -0.054860 -0.223606   \n",
      "17    0.795110  0.087122  0.023247 -0.069767  0.000202 -0.051105  0.793501   \n",
      "18    0.356791 -0.064555  0.192826 -0.072493 -0.010245 -0.054348 -0.130672   \n",
      "19    0.381966  0.148775 -0.068143 -0.038173 -0.011632 -0.054771  0.885887   \n",
      "20    0.534872 -0.091226  0.157612 -0.072945 -0.011955  0.019322 -0.297112   \n",
      "21    0.465888 -0.043904  0.172202 -0.072928 -0.011893 -0.054850 -0.037739   \n",
      "22    0.005564  0.182380 -0.068226 -0.072942 -0.011945 -0.054866  0.894427   \n",
      "23    0.633348 -0.084797 -0.006510 -0.072799 -0.011401  0.198710 -0.269750   \n",
      "24    0.010924 -0.091180 -0.068180  0.211943 -0.011771 -0.054813 -0.223604   \n",
      "25    0.704642 -0.090817  0.106244 -0.072522 -0.010338  0.076537 -0.352856   \n",
      "26    0.647399  0.093799  0.025300 -0.072743 -0.011184 -0.054634  0.792888   \n",
      "27    0.247474 -0.078904  0.206805 -0.072073 -0.008664 -0.053866 -0.185649   \n",
      "28    0.007305 -0.091210  0.222472 -0.072928 -0.011890 -0.054850 -0.223607   \n",
      "29    0.067653  0.179897 -0.067574 -0.072296 -0.009472 -0.054100  0.894427   \n",
      "30    0.681997  0.117427 -0.014587 -0.072799 -0.011399 -0.037619  0.869886   \n",
      "31    1.145677  0.009998  0.048917 -0.070436 -0.002393  0.014781  0.448988   \n",
      "32    0.079900  0.179331 -0.067420 -0.072141 -0.008895 -0.053944  0.894427   \n",
      "33    0.007045 -0.091212  0.222481 -0.072930 -0.011899 -0.054852 -0.223606   \n",
      "34    0.360672  0.151840 -0.036094 -0.072836 -0.011543 -0.054743  0.887636   \n",
      "35    1.037819 -0.024549  0.002487  0.073137 -0.011582 -0.054755  0.102658   \n",
      "36    0.776809 -0.089648  0.052815 -0.071320 -0.005782  0.133385 -0.357952   \n",
      "37    0.471027  0.154594 -0.060873 -0.065680  0.015821 -0.046420  0.894427   \n",
      "38    0.028698 -0.091017  0.221653 -0.072727 -0.011126 -0.054613 -0.223606   \n",
      "39    0.258834 -0.090568  0.205157 -0.057950 -0.009352 -0.054071 -0.238430   \n",
      "40    0.755892  0.051617 -0.067200 -0.071950 -0.008197  0.100451  0.596893   \n",
      "41    0.577605 -0.045226 -0.066152 -0.070911 -0.004175  0.214416 -0.045760   \n",
      "42    0.766328  0.051485 -0.067013  0.059842 -0.007313 -0.053469  0.598130   \n",
      "43    0.396155 -0.085611 -0.062368 -0.067153  0.993864 -0.048149 -0.223335   \n",
      "44    0.015707 -0.091139 -0.068135 -0.072853 -0.011608  0.276953 -0.223605   \n",
      "45    0.524005  0.150427 -0.059864 -0.064549  0.020576 -0.045273  0.894427   \n",
      "46    1.014166  0.060776 -0.047526  0.021752 -0.011834 -0.041253  0.748355   \n",
      "47    0.635807 -0.039562  0.159687 -0.070326 -0.002055 -0.051841 -0.016660   \n",
      "48    0.005129 -0.091227  0.222545 -0.072946 -0.011958 -0.054870 -0.223606   \n",
      "49    0.305029  0.158182 -0.068197 -0.047813 -0.011839 -0.054834  0.890346   \n",
      "\n",
      "       loss1     loss2     loss3     loss4  \n",
      "0   0.460085 -0.362576 -0.362578 -0.362575  \n",
      "1  -0.223607 -0.223604 -0.223608 -0.223607  \n",
      "2  -0.223606 -0.223607 -0.223608  0.894427  \n",
      "3  -0.269913 -0.269908 -0.269922 -0.071362  \n",
      "4   0.815769 -0.322317 -0.322318 -0.322317  \n",
      "5  -0.056895 -0.166732 -0.323851 -0.323847  \n",
      "6  -0.223607 -0.223608 -0.223608 -0.223605  \n",
      "7   0.830724 -0.038568 -0.507026 -0.215657  \n",
      "8  -0.349193 -0.349193 -0.349196  0.730523  \n",
      "9   0.714125 -0.257310 -0.395266  0.333703  \n",
      "10 -0.321483 -0.148760 -0.321484 -0.082545  \n",
      "11  0.894427 -0.223606 -0.223607 -0.223607  \n",
      "12  0.883672 -0.270740 -0.270742 -0.087502  \n",
      "13 -0.223627 -0.223659 -0.223665 -0.223477  \n",
      "14  0.321546  0.124816 -0.661263 -0.351172  \n",
      "15 -0.267289  0.737877 -0.477426 -0.275987  \n",
      "16  0.894427 -0.223607 -0.223608 -0.223606  \n",
      "17  0.201261 -0.331668 -0.331745 -0.331348  \n",
      "18  0.889401 -0.252894 -0.252923 -0.252912  \n",
      "19 -0.261269 -0.102083 -0.261268 -0.261267  \n",
      "20  0.856723 -0.297113 -0.297114  0.034616  \n",
      "21  0.874689 -0.278982 -0.278986 -0.278982  \n",
      "22 -0.223607 -0.223607 -0.223608 -0.223606  \n",
      "23  0.018734 -0.304885 -0.304894  0.860795  \n",
      "24 -0.223609  0.894427 -0.223608 -0.223606  \n",
      "25  0.711095 -0.352881 -0.352891  0.347533  \n",
      "26  0.202553 -0.331810 -0.331819 -0.331812  \n",
      "27  0.893577 -0.235940 -0.236003 -0.235986  \n",
      "28  0.894427 -0.223606 -0.223607 -0.223607  \n",
      "29 -0.223637 -0.223609 -0.223618 -0.223563  \n",
      "30 -0.023996 -0.308457 -0.308466 -0.228967  \n",
      "31  0.535987 -0.505125 -0.505301  0.025452  \n",
      "32 -0.223622 -0.223578 -0.223608 -0.223619  \n",
      "33  0.894427 -0.223607 -0.223608 -0.223607  \n",
      "34 -0.115391 -0.257413 -0.257419 -0.257413  \n",
      "35  0.101514  0.734132 -0.469157 -0.469147  \n",
      "36  0.398594 -0.358078 -0.358191  0.675627  \n",
      "37 -0.223733 -0.223494 -0.223639 -0.223561  \n",
      "38  0.894427 -0.223607 -0.223615 -0.223599  \n",
      "39  0.893195 -0.177864 -0.238465 -0.238435  \n",
      "40 -0.364121 -0.364206 -0.364313  0.495747  \n",
      "41 -0.276836 -0.276848 -0.276887  0.876331  \n",
      "42 -0.364223  0.494363 -0.364113 -0.364157  \n",
      "43 -0.223796 -0.223592  0.894427 -0.223704  \n",
      "44 -0.223606 -0.223605 -0.223611  0.894427  \n",
      "45 -0.224179 -0.223282 -0.222938 -0.224027  \n",
      "46 -0.271114  0.278215 -0.420746 -0.334711  \n",
      "47  0.870040 -0.284352 -0.284567 -0.284461  \n",
      "48  0.894427 -0.223607 -0.223607 -0.223607  \n",
      "49 -0.250131 -0.139952 -0.250133 -0.250131  \n",
      "CPU times: user 4.22 s, sys: 145 ms, total: 4.37 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Dynamic Feature Generation - Document/Topic entropy, GOSS/LOSS scores\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import scipy as scipy\n",
    "from math import sqrt\n",
    "\n",
    "# create lda model\n",
    "def create_lda(num_topics,tf_matrix):\n",
    "    return LatentDirichletAllocation(n_components=num_topics,max_iter=5,\n",
    "                                     learning_method='online',learning_offset=50,\n",
    "                                     random_state=0).fit(tf_matrix)\n",
    "\n",
    "#return normalized topic-word distribution\n",
    "def create_tw_dist(model):\n",
    "    normTWDist = model.components_ / model.components_.sum(axis=1)[:, np.newaxis]\n",
    "     \n",
    "    return normTWDist\n",
    "\n",
    "#return normalized document-topic distribution\n",
    "def create_dt_dist(model, tf_matrix):\n",
    "    normDTDist = model.transform(tf_matrix)\n",
    "    \n",
    "    return normDTDist\n",
    "\n",
    "#calculate entropy for a given sequence of values\n",
    "def entropy_single(x):\n",
    "    return scipy.stats.entropy(x)\n",
    "\n",
    "#calculate entropy for an entire document-topic distribution\n",
    "def entropy_all(dt_dist):\n",
    "    np_entropy = np.apply_along_axis(entropy_single, axis=1, arr=dt_dist)\n",
    "    \n",
    "    return pd.DataFrame(np_entropy, columns=['dt_entropy'])\n",
    "\n",
    "#GOSS/LOSS features\n",
    "#calculate GOSS score for a single particular user/topic (i/k) combination\n",
    "def single_goss(topic_dist,i,k):\n",
    "    \n",
    "    #1.0 return mu(xk) for specific topic, sum topic probabilities for all users, average across all users\n",
    "    mu_xk = np.sum(topic_dist[:,k]) / topic_dist.shape[0]\n",
    "    \n",
    "    #2.0 GOSS equation numerator\n",
    "    goss_numerator = topic_dist[i,k] - mu_xk\n",
    "    \n",
    "    #3.0 for all users specific topic probability:\n",
    "    # - sum the squared difference of their relevant topic probability\n",
    "    # - find the square of this sum\n",
    "    goss_denominator = 0\n",
    "    for user_prob in topic_dist[:,k]:\n",
    "        goss_denominator += (user_prob - mu_xk) ** 2\n",
    "    \n",
    "    #3.1 find sqrt of goss_denominator\n",
    "    goss_denominator = sqrt(goss_denominator)\n",
    "    \n",
    "    #4.0 divide numerator/denominator to find final GOSS score for user/topic combination\n",
    "    return goss_numerator / goss_denominator\n",
    "    \n",
    "#calculate GOSS scores for a particular topic distribution\n",
    "def all_goss(topic_dist):  \n",
    "    goss=[]\n",
    "    topics = range(topic_dist.shape[1])\n",
    "    topic_labels = list('goss' + str(each) for each in topics)\n",
    "    \n",
    "    for user in range(topic_dist.shape[0]): #each user\n",
    "        temp_goss = list(single_goss(topic_dist,user,topic) for topic in topics) #calculate all GOSS scores per topic\n",
    "        goss.append(temp_goss) #store all GOSS via nested lists\n",
    "\n",
    "    np_goss = np.array(goss) #recast as np array..\n",
    "    return pd.DataFrame(goss, columns=topic_labels) #and then to pandas df..\n",
    "\n",
    "#calculate loss score for a particular user/topic (i/k) combination\n",
    "def single_loss(topic_dist,i,k):\n",
    "    #1.0 return mu(xi) for specific user, sum topic probabilities, return average\n",
    "    mu_xi = np.sum(topic_dist[i,:]) / topic_dist.shape[1]\n",
    "    \n",
    "    #2.0 calculate muXI diff - GOSS equation numerator\n",
    "    loss_numerator = topic_dist[i,k] - mu_xi\n",
    "    \n",
    "    #3.0 for all topics (k) and a specific user (i):\n",
    "    # - sum the squared difference of all associated topic probabilities and mu(xi)\n",
    "    # - find the square of this sum\n",
    "    loss_denominator = 0\n",
    "    for user_prob in topic_dist[i,:]:\n",
    "        loss_denominator += (user_prob - mu_xi) ** 2\n",
    "    \n",
    "    #3.1 find sqrt of loss denominator\n",
    "    loss_denominator = sqrt(loss_denominator)\n",
    "    \n",
    "    #4.0 divide loss numerator by loss denominator to find loss score for specific user\n",
    "    return loss_numerator / loss_denominator\n",
    "    \n",
    "#calculate GOSS scores for all users\n",
    "def all_loss(topic_dist):  \n",
    "    loss=[]\n",
    "    topics = range(topic_dist.shape[1])\n",
    "    topic_labels = list('loss' + str(each) for each in topics)\n",
    "    \n",
    "    for user in range(topic_dist.shape[0]): #each user\n",
    "        temp_loss = list(single_loss(topic_dist,user,topic) for topic in topics) #calculate all loss scores per topic\n",
    "        loss.append(temp_loss) #store all loss scores for each user via nested lists\n",
    "    \n",
    "    np_loss = np.array(loss) #cast to np array..\n",
    "    return pd.DataFrame(np_loss, columns=topic_labels) #and finally to pandas df..\n",
    "\n",
    "def generate_dynamic_features(tf_matrix, lda_topics):\n",
    "    #fit LDA model using count vector\n",
    "    lda = create_lda(lda_topics, tf_matrix)\n",
    "    \n",
    "    #retrieve document/topic distribution\n",
    "    dt_dist = create_dt_dist(lda, tf_matrix)\n",
    "    \n",
    "    #retrieve entropy for topic distribution\n",
    "    dt_entropy = entropy_all(dt_dist)\n",
    "    \n",
    "    #retrieve GOSS and LOSS scores\n",
    "    goss_df = all_goss(dt_dist)\n",
    "    loss_df = all_loss(dt_dist)\n",
    "    \n",
    "    #glue new features together into single df\n",
    "    dynamic_features = pd.concat([dt_entropy, goss_df, loss_df], axis=1)\n",
    "    return export_csv(dynamic_features,'../../data_sets/honey_pot/final_features/dynamic_features.csv')\n",
    "    \n",
    "df = generate_dynamic_features(tf_matrix, 5)\n",
    "\n",
    "print(df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preliminary clustering\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# define import directories\n",
    "dirs = {'static_features': '../../data_sets/honey_pot/final_features/static_features.csv',\n",
    "       'dynamic_features':'../../data_sets/honey_pot/final_features/dynamic_features.csv'}\n",
    "\n",
    "#read in and join static and dynamic features \n",
    "def consolidate_features(static_features, dynamic_features):\n",
    "    static = pd.read_csv(static_features, index_col=0).reset_index(drop=True)\n",
    "    dynamic = pd.read_csv(dynamic_features, index_col=0)\n",
    "    \n",
    "    return pd.concat([static, dynamic], axis=1) #join features along axis\n",
    "    \n",
    "#customize features contained within df\n",
    "def choose_features(df, feature_list):\n",
    "    return df.loc[:, feature_list]\n",
    "\n",
    "#scale features to ensure clustering is not skewed\n",
    "def scale_features(df):\n",
    "    scaler = StandardScaler()\n",
    "    df = df.as_matrix()\n",
    "    return scaler.fit_transform(df)\n",
    "\n",
    "#perform clustering on df_matrix, append resultant cluster labels to original df\n",
    "def kmeans(df, df_matrix, n_clusters):\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=42).fit(df_matrix) #create/fit kmeans to matrix\n",
    "    \n",
    "    df['cluster'] = km.labels_ #augment cluster result as attribute\n",
    "#     df['user_id'] = df.index #ensuer user ID retained before segmentation\n",
    "    \n",
    "    return segment_df(df, n_clusters)\n",
    "\n",
    "#segment df based upon cluster allocation\n",
    "def segment_df(df, n_clusters):\n",
    "    segmented_df = [] #contain segmented df as list\n",
    "    \n",
    "    #segment df based upon cluster\n",
    "    for cluster in range(n_clusters):\n",
    "        segmented_df.append(df.loc[df['cluster'] == cluster])\n",
    "\n",
    "    return segmented_df\n",
    "\n",
    "#perform preliminary clustering, return list of cluster-based df's\n",
    "def distil_clusters():\n",
    "    all_df = consolidate_features(dirs['static_features'], dirs['dynamic_features'])\n",
    "    select_df = choose_features(all_df, ['dt_entropy','totalNumOfUniqWords'])\n",
    "    \n",
    "    df_matrix = scale_features(select_df)\n",
    "    return kmeans(all_df, df_matrix, 3)\n",
    "\n",
    "all_df = distil_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/cluster0.csv\n",
      "./test/cluster1.csv\n",
      "./test/cluster2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "#export single dataframe\n",
    "def export_frame(df, file_path):\n",
    "    df.to_csv(file_path)\n",
    "    return df\n",
    "\n",
    "#clear parent directory of all files, export clustered frames\n",
    "def export_frames_destructive(frames, folder_location):\n",
    "    files = glob.glob('./test/*') #clear holding dir\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    for idx,df in enumerate(frames):\n",
    "        f_name = folder_location + 'cluster' + str(idx) + '.csv'\n",
    "        export_frame(df, f_name)\n",
    "\n",
    "export_frames_destructive(all_df, './test/')\n",
    "\n",
    "# for df in all_df:\n",
    "#     print(type(df))\n",
    "\n",
    "#apply final classification\n",
    "# print(all_df[0].columns)\n",
    "\n",
    "# for each in all_df:\n",
    "#     print(each['UserType'].astype(bool).sum(axis=0)) #retrieve number of non-zeros in usertype column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster1.csv\n",
      "cluster2.csv\n",
      "cluster3.csv\n",
      "cluster4.csv\n"
     ]
    }
   ],
   "source": [
    "l = [1,2,3,4]\n",
    "\n",
    "for df, val in enumerate(l):\n",
    "    print('cluster' + str(val) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded utilities\n",
      "CPU times: user 167 µs, sys: 11 µs, total: 178 µs\n",
      "Wall time: 186 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#utility functions\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#entire x/y partition for cross fold validation\n",
    "def course_split(df):\n",
    "    return df.drop(['UserType'], axis=1), df['UserType']\n",
    "\n",
    "#x/y splits further partitioned into train/test\n",
    "def fine_split(df):\n",
    "    #partition data\n",
    "    y = df['UserType']\n",
    "    X = df.drop(['UserType'], axis=1)\n",
    "    X_mat = X.as_matrix()\n",
    "    return train_test_split(X_mat, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "#evaluate models performance using kfold cross validation\n",
    "def kfold(model, model_name, X, y):\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.4, random_state=42) #define cv iterator parameters (stratify?)\n",
    "    scores = cross_val_score(model, X, y, cv=cv)\n",
    "    \n",
    "    #retrieve trained model accuracy using cross fold validation score - using all data \n",
    "    print(\"{0} Accuracy: {1:.2f} (+/- {2:.2f})\".format(model_name, scores.mean(), scores.std() * 2))\n",
    "    \n",
    "#evaluate models performance using classification report and confusion matrix\n",
    "def metrics(model, X_train, X_test, y_train, y_test):\n",
    "    #classification report and confusion matrix - using train/test partitions\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "print('loaded utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 µs, sys: 0 ns, total: 16 µs\n",
      "Wall time: 19.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#generate models for a given df\n",
    "def generate_models(df, df_name):\n",
    "    print('Generating models for {}'.format(df_name))\n",
    "    \n",
    "    models = [DecisionTreeClassifier(), RandomForestClassifier(), AdaBoostClassifier(), LinearSVC()]\n",
    "    model_names = [\"Decision Tree\", \"Random Forest\", \"Adaboost\", \"LinearSVC\"]\n",
    "\n",
    "    #partion dataframe\n",
    "    X,y = course_split(df)\n",
    "    X_train,X_test,y_train,y_test = fine_split(df)\n",
    "\n",
    "    #evaluate all models\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        kfold(model, model_name, X, y)\n",
    "        metrics(model,X_train,X_test,y_train,y_test)\n",
    "    \n",
    "#generate models for a list of dataframes\n",
    "def generate_all(df_list):\n",
    "    for df in df_list:\n",
    "        generate_models(df, 'test_name')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "b = [1,2,3,4]\n",
    "\n",
    "def c(d):\n",
    "    return d + 1\n",
    "\n",
    "for each in b:\n",
    "    a.append(c(each))\n",
    "    \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating models for test_name\n",
      "Decision Tree Accuracy: 0.79 (+/- 0.22)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80        11\n",
      "          1       0.50      0.20      0.29         5\n",
      "\n",
      "avg / total       0.65      0.69      0.64        16\n",
      "\n",
      "Confusion matrix:\n",
      " [[10  1]\n",
      " [ 4  1]]\n",
      "Random Forest Accuracy: 0.79 (+/- 0.15)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      1.00      0.85        11\n",
      "          1       1.00      0.20      0.33         5\n",
      "\n",
      "avg / total       0.82      0.75      0.69        16\n",
      "\n",
      "Confusion matrix:\n",
      " [[11  0]\n",
      " [ 4  1]]\n",
      "Adaboost Accuracy: 0.80 (+/- 0.18)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80        11\n",
      "          1       0.50      0.20      0.29         5\n",
      "\n",
      "avg / total       0.65      0.69      0.64        16\n",
      "\n",
      "Confusion matrix:\n",
      " [[10  1]\n",
      " [ 4  1]]\n",
      "LinearSVC Accuracy: 0.56 (+/- 0.39)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        11\n",
      "          1       0.31      1.00      0.48         5\n",
      "\n",
      "avg / total       0.10      0.31      0.15        16\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 0 11]\n",
      " [ 0  5]]\n",
      "Generating models for test_name\n",
      "Decision Tree Accuracy: 0.60 (+/- 0.29)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.50      0.57         4\n",
      "          1       0.78      0.88      0.82         8\n",
      "\n",
      "avg / total       0.74      0.75      0.74        12\n",
      "\n",
      "Confusion matrix:\n",
      " [[2 2]\n",
      " [1 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samhardyhey/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.59 (+/- 0.31)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.25      0.29         4\n",
      "          1       0.67      0.75      0.71         8\n",
      "\n",
      "avg / total       0.56      0.58      0.57        12\n",
      "\n",
      "Confusion matrix:\n",
      " [[1 3]\n",
      " [2 6]]\n",
      "Adaboost Accuracy: 0.63 (+/- 0.23)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.25      0.33         4\n",
      "          1       0.70      0.88      0.78         8\n",
      "\n",
      "avg / total       0.63      0.67      0.63        12\n",
      "\n",
      "Confusion matrix:\n",
      " [[1 3]\n",
      " [1 7]]\n",
      "LinearSVC Accuracy: 0.47 (+/- 0.40)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         4\n",
      "          1       0.67      1.00      0.80         8\n",
      "\n",
      "avg / total       0.44      0.67      0.53        12\n",
      "\n",
      "Confusion matrix:\n",
      " [[0 4]\n",
      " [0 8]]\n",
      "Generating models for test_name\n",
      "Decision Tree Accuracy: 0.75 (+/- 0.30)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.50      0.57         4\n",
      "          1       0.80      0.89      0.84         9\n",
      "\n",
      "avg / total       0.76      0.77      0.76        13\n",
      "\n",
      "Confusion matrix:\n",
      " [[2 2]\n",
      " [1 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samhardyhey/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.72 (+/- 0.21)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.25      0.29         4\n",
      "          1       0.70      0.78      0.74         9\n",
      "\n",
      "avg / total       0.59      0.62      0.60        13\n",
      "\n",
      "Confusion matrix:\n",
      " [[1 3]\n",
      " [2 7]]\n",
      "Adaboost Accuracy: 0.75 (+/- 0.22)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.50      0.67         4\n",
      "          1       0.82      1.00      0.90         9\n",
      "\n",
      "avg / total       0.87      0.85      0.83        13\n",
      "\n",
      "Confusion matrix:\n",
      " [[2 2]\n",
      " [0 9]]\n",
      "LinearSVC Accuracy: 0.55 (+/- 0.36)\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         4\n",
      "          1       0.69      1.00      0.82         9\n",
      "\n",
      "avg / total       0.48      0.69      0.57        13\n",
      "\n",
      "Confusion matrix:\n",
      " [[0 4]\n",
      " [0 9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samhardyhey/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "generate_all(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
